{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个文件处理的过程文件类型的变化\n",
    "\n",
    "file\n",
    "<langchain.document_loaders*> \n",
    "\n",
    "经过.load()加载操作\n",
    "\n",
    "pages\n",
    "\n",
    "<list*>\n",
    "\n",
    "pages里每一个page是\n",
    "langchain.documents.Document类型\n",
    "包括了metadata属性和page_content属性\n",
    "后者是主要内容\n",
    "\n",
    "清洗数据以后返回的是\n",
    "list\n",
    "langchain.documents.Document类型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(\"/root/RAG_program/README.md\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/RAG_program/src/data_process/loader.py:46: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-unstructured package and should be used instead. To use it run `pip install -U :class:`~langchain-unstructured` and import as `from :class:`~langchain_unstructured import UnstructuredLoader``.\n",
      "  loaders.append(UnstructuredFileLoader(current_file_path))\n"
     ]
    }
   ],
   "source": [
    "from data_process.loader import *\n",
    "loaders = load_content(\"raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(loaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process.processdata import *\n",
    "cleandata = cleanData(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(cleandata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cleandata[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = cleandata[2:]# 只测试markdown文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第八章聊天机器人\n",
      "大型语言模型带给我们的激动人心的一种可能性是，我们可以通过它构建定制的聊天机器人（Chatbot），而且只需很少的工作量。在这一章节的探索中，我们将带你了解如何利用会话形式，与具有个性化特性（或专门为特定任务或行为设计）的聊天机器人进行深度对话。像ChatGPT这样的聊天模型实际上是组装成以一系列消息作为输入，并返回一个模型生成的消息作为输出的。这种聊天格式原本的设计目标是简便多轮对话，但我们通过之前的学习可以知道，它对于不会涉及任何对话的单轮任务也同样有用。一、给定身份\n",
      "接下来，我们将定义两个辅助函数。第一个方法已经陪伴了您一整个教程，即get_completion，其适用于单轮对话。我们将Prompt放入某种类似用户消息的对话框中。另一个称为get_completion_from_messages，传入一个消息列表。这些消息可以来自大量不同的角色(roles)，我们会描述一下这些角色。第一条消息中，我们以系统身份发送系统消息(systemmessage)，它提供了一个总体的指示。系统消息则有助于设置助手的行为和角色，并作为对话的高级指示。你可以想象它在助手的耳边低语，引导它的回应，而用户不会注意到系统消息。因此，作为用户，如果你曾经使用过ChatGPT，您可能从来不知道ChatGPT的系统消息是什么，这是有意为之的。系统消息的好处是为开发者提供了一种方法，在不让请求本身成为对话的一部分的情况下，引导助手并指导其回应。在ChatGPT网页界面中，您的消息称为用户消息，而ChatGPT的消息称为助手消息。但在构建聊天机器人时，在发送了系统消息之后，您的角色可以仅作为用户(user)；也可以在用户和助手(assistant)之间交替，从而提供对话上下文。```pythonimportopenai下文第一个函数即tool工具包中的同名函数，此处展示出来以便于读者对比defget_completion(prompt,model=\"gpt-3.5-turbo\"):messages=[{\"role\":\"user\",\"content\":prompt}]response=openai.ChatCompletion.create(model=model,messages=messages,temperature=0,#控制模型输出的随机程度)returnrespo\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第八章聊天机器人\n",
      "大型语言模型带给我们的激动人心的一种可能性是，我们可以通过它构建定制的聊天机器人（Chatbot），而且只需很少的工作量。在这一章节的探索中，我们将带你了解如何利用会话形式，与具有个性化特性（或专门为特定任务或行为设计）的聊天机器人进行深度对话。像ChatGPT这样的聊天模型实际上是组装成以一系列消息作为输入，并返回一个模型生成的消息作为输出的。这种聊天格式原本的设计目标是简便多轮对话，但我们通过之前的学习可以知道，它对于不会涉及任何对话的单轮任务也同样有用。一、给定身份\n",
      "接下来，我们将定义两个辅助函数。第一个方法已经陪伴了您一整个教程，即get_completion，其适用于单轮对话。我们将Prompt放入某种类似用户消息的对话框中。另一个称为get_completion_from_messages，传入一个消息列表。这些消息可以来自大量不同的角色(roles)，我们会描述一下这些角色。第一条消息中，我们以系统身份发送系统消息(systemmessage)，它提供了一个总体的指示。系统消息则有助于设置助手的行为和角色，并作为对话的高级指示。你可以想象它在助手的耳边低\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语，引导它的回应，而用户不会注意到系统消息。因此，作为用户，如果你曾经使用过ChatGPT，您可能从来不知道ChatGPT的系统消息是什么，这是有意为之的。系统消息的好处是为开发者提供了一种方法，在不让请求本身成为对话的一部分的情况下，引导助手并指导其回应。在ChatGPT网页界面中，您的消息称为用户消息，而ChatGPT的消息称为助手消息。但在构建聊天机器人时，在发送了系统消息之后，您的角色可以仅作为用户(user)；也可以在用户和助手(assistant)之间交替，从而提供对话上下文。```pythonimportopenai下文第一个函数即tool工具包中的同名函数，此处展示出来以便于读者对比defget_completion(prompt,model=\"gpt-3.5-turbo\"):messages=[{\"role\":\"user\",\"content\":prompt}]response=openai.ChatCompletion.create(model=model,messages=messages,temperature=0,#控制模型输出的随机程度)returnrespo\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[500:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割特点\n",
    "​优先保留语义完整性：如果文本中存在换行符（\\n）或段落（\\n\\n），分割器会优先在这些位置切分，即使切分后的块小于 chunk_size。\n",
    "若文本中存在多个短段落（例如每个段落仅 200 字符），分割器会在段落末尾切分，导致每个块的字符数远小于 chunk_size。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档分割\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitor = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "split = text_splitor.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "print(len(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第八章聊天机器人\n",
      "大型语言模型带给我们的激动人心的一种可能性是，我们可以通过它构建定制的聊天机器人（Chatbot），而且只需很少的工作量。在这一章节的探索中，我们将带你了解如何利用会话形式，与具有个性化特性（或专门为特定任务或行为设计）的聊天机器人进行深度对话。像ChatGPT这样的聊天模型实际上是组装成以一系列消息作为输入，并返回一个模型生成的消息作为输出的。这种聊天格式原本的设计目标是简便多轮对话，但我们通过之前的学习可以知道，它对于不会涉及任何对话的单轮任务也同样有用。一、给定身份\n"
     ]
    }
   ],
   "source": [
    "print(split[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_from_messages，传入一个消息列表。这些消息可以来自大量不同的角色(roles)，我们会描述一下这些角色。第一条消息中，我们以系统身份发送系统消息(systemmessage)，它提供了一个总体的指示。系统消息则有助于设置助手的行为和角色，并作为对话的高级指示。你可以想象它在助手的耳边低语，引导它的回应，而用户不会注意到系统消息。因此，作为用户，如果你曾经使用过ChatGPT，您可能从来不知道ChatGPT的系统消息是什么，这是有意为之的。系统消息的好处是为开发者提供了一种方法，在不让请求本身成为对话的一部分的情况下，引导助手并指导其回应。在ChatGPT网页界面中，您的消息称为用户消息，而ChatGPT的消息称为助手消息。但在构建聊天机器人时，在发送了系统消息之后，您的角色可以仅作为用户(user)；也可以在用户和助手(assistant)之间交替，从而提供对话上下文。\n"
     ]
    }
   ],
   "source": [
    "print(split[1].page_content[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='sivebatterylife,buttoothbrushheadistoosmall.Gooddealifboughtaround$50.3Thereviewerfoundthepriceincreaseafterthesaledisappointingandnoticedadecreaseinqualityovertime.' metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/4. 文本概括 Summarizing.md'}\n"
     ]
    }
   ],
   "source": [
    "print(split[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用持久化向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from embedding.zhipu_embedding import ZhipuAIEmbeddings\n",
    "from utils.path_utils import *\n",
    "\n",
    "# 初始化embedding模型\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "# 加载持久化向量数据库\n",
    "vector_db_path = get_vector_store_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20005/1481020751.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "vector_db = Chroma(\n",
    "    persist_directory=vector_db_path,\n",
    "    embedding_function=embedding,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430\n"
     ]
    }
   ],
   "source": [
    "print(vector_db._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介')]\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.similarity_search(\"人工智能\")[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), 0.25333705278682617), (Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), 0.25333705278682617), (Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), 0.25333705278682617)]\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.similarity_search_with_relevance_scores(\"人工智能\", k=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = vector_db.similarity_search_with_relevance_scores(\"家具\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = vector_db.max_marginal_relevance_search(\"如何实现聊天机器人\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/9. 总结 Summary.md'}, page_content='第九章总结\\n恭喜您完成了本书第一单元内容的学习！总的来说，在第一部分中，我们学习并掌握了关于Prompt的两个核心原则：编写清晰具体的指令；如果适当的话，给模型一些思考时间。您还学习了迭代式Prompt开发的方法，并了解了如何找到适合您应用程序的Prompt的过程是非常关键的。我们还讨论了大型语言模型的许多功能，包括摘要、推断、转换和扩展。您也学习了如何搭建个性化的聊天机器人。在第一部分中，您的收获应该颇丰，希望通过第一部分学习能为您带来愉悦的体验。我们期待您能灵感迸发，尝试创建自己的应用。请大胆尝试，并分享给我们您的想法。您可以从一个微型项目开始，或许它具备一定的实用性，或者仅仅是一项有趣的创新。请利用您在第一个项目中得到的经验，去创造更优秀的下一项目，以此类推。如果您已经有一个宏大的项目设想，那么，请毫不犹豫地去实现它。最后，希望您在完成第一部分的过程中感到满足，感谢您的参与。我们热切期待着您的惊艳作品。接下来，我们将进入第二部分的学习！'), Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/1. 简介 Introduction.md'}, page_content='第一章简介'), Document(metadata={'source': '/root/RAG_program/data/raw/prompt_engineering/7. 文本扩展 Expanding.md'}, page_content='tourcustomerserviceteam,andtheywilldotheirbesttoassistyou.Thankyouonceagainforyourreview.Wevalueyourfeedbackandappreciateyourloyaltytoourbrand.Ifyouhaveanyfurtherquestionsorconcerns,pleasedonothesitatetocontactus.Bestregards,AIcustomeragent2.1引入温度系数pythonprompt=f\"\"\"YouareacustomerserviceAIassistant.Yourtaskistosendanemailreplytoavaluedcustomer.Giventhecustomeremaildelimitedby,\\\\Generateareplytothankthecustomerfortheirreview.Ifthesentimentispositiveorneutral,thankthemfor\\\\theirreview.Ifthesentiment')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第九章总结\n",
      "恭喜您完成了本书第一单元内容的学习！总的来说，在第一部分中，我们学习并掌握了关于Prompt的两个核心原则：编写清晰具体的指令；如果适当的话，给模型一些思考时间。您还学习了迭代式Prompt开发的方法，并了解了如何找到适合您应用程序的Prompt的过程是非常关键的。我们还讨论了大型语言模型的许多功能，包括摘要、推断、转换和扩展。您也学习了如何搭建个性化的聊天机器人。在第一部分中，您的收获应该颇丰，希望通过第一部分学习能为您带来愉悦的体验。我们期待您能灵感迸发，尝试创建自己的应用。请大胆尝试，并分享给我们您的想法。您可以从一个微型项目开始，或许它具备一定的实用性，或者仅仅是一项有趣的创新。请利用您在第一个项目中得到的经验，去创造更优秀的下一项目，以此类推。如果您已经有一个宏大的项目设想，那么，请毫不犹豫地去实现它。最后，希望您在完成第一部分的过程中感到满足，感谢您的参与。我们热切期待着您的惊艳作品。接下来，我们将进入第二部分的学习！\n"
     ]
    }
   ],
   "source": [
    "print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
