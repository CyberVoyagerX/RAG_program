{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, Runnable\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from embedding.zhipu_embedding import ZhipuAIEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from utils.path_utils import get_vector_store_dir\n",
    "# from retriever import retriever\n",
    "from utils.env_loader import get_env\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46985/1611650476.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  model = ChatOpenAI(\n",
      "/tmp/ipykernel_46985/1611650476.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vector_db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "api_key = get_env(\"ZHIPUAI_API_KEY\")\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "vector_db = Chroma(\n",
    "    persist_directory=get_vector_store_dir(),\n",
    "    embedding_function=ZhipuAIEmbeddings(),\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "使用下文内容来回答问题，不知道则直接回答不知道，不要试图编造答案。最多使用三句话，答案简明扼要。总在回答的最后说\"谢谢你的提问！\"。\n",
    "{context}\n",
    "问题:{question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT=PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "\n",
    "# 加载检索器\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model,\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869\n"
     ]
    }
   ],
   "source": [
    "print(vector_db._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46985/2071198752.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"query\":\"什么是大模型\"})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\":\"什么是大模型\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型，通常指的是参数规模极大的机器学习模型，例如大型语言模型（LLM），它们能在大量数据上学习复杂的模式，用于预测下一个单词或执行特定任务。这些模型具有强大的泛化和应用能力，可以应用于聊天机器人、文本转换、推理等多个领域。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
